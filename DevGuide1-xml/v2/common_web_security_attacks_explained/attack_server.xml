<sect1>
	<title>Attacks against the Web Server</title>
	<para>The first set of attacks that an attacker will typically launch against a web application will be targeted at the underlying web server. When trying to attack the server externally, an attacker will try to identify the technologies being used by the web application. These include the underlying web server, the operating system, the business logic components, the back-end database, and the programming language for the web application itself.
	</para>
	<para>Some smart guesses can be made. For instance, if the web application is coded in ASP, there is a very high probability that the web server is IIS, and the operating system is one of the Windows server versions. There is also a good chance that in this case, the back-end database is probably Microsoft's SQL Server.
	</para>
	<para>Such preliminary guesses can be further narrowed down by using some of the following techniques to enumerate more information:
	</para>
	<para>
Banner grabbing: This may reveal the web server software and version. However, it is relatively easy to change the banner of the real web server with that of some other, in order to try and throw the attacker off track. Most port scanners such as nmap1 or Superscan2 have options to enable banner grabbing during the port scan itself.
Web Server Fingerprinting: Similar to the concept of OS fingerprinting, HTTP fingerprinting tries to determine the remote web server based on its responses to HTTP requests. Thus, even if the banner is modified, tools such as httprint3 will attempt to identify the web server as accurately as possible.
Information disclosure: By inducing an error in the web application or the web server, the attacker can obtain information about the underlying technology. For instance, an error induced by supplying unexpected input values to an ASP page might reveal the back-end database to be Oracle or SQL Server. Another vulnerability that leads to code disclosure is if there are scripts on the web server, that it is not configured to preprocess. For instance, in one case where the site was predominantly coded in PHP, there were a few Perl scripts left lying around, probably from legacy code. Accessing one of the Perl scripts revealed its source including the username and password used to connect to the back-end database. This is also true of .inc files, which could contain sensitive information that can be read because these files are not pre-processed by IIS.
Operating System Fingerprinting: The attacker may use nmap to try and fingerprint the operating system based on its specific implementation of the TCP/IP stack
Once the process of technology identification is complete, the attacker will try to launch attacks against the web server, which exploit configuration mistakes, sample scripts, third-party components such as shopping cards, etc.
</para>
	<para>One of the most popular open-source tools for testing web applications is Nikto4, which contains an extensive database of vulnerabilities against various web servers. The usual suspect in vulnerability assessment exercises, Nessus, also does a pretty good job of determine vulnerabilities in the web server, operating system, and other technologies. In fact, there are now plugins for Nessus that will attempt to detect the vulnerability of the web application to SQL injection and HTML injection attacks.
	</para>
	<para>At the next stage, the attacker will survey the whole web application to try and determine the general design logic being followed. This is typically done by downloading the entire website onto the local hard drive, and then studying the files to figure out the structure of the web site. For instance, does the web site keep the scripts in a central /admin/ or /scripts/ or /cgi-bin/ folder, or are they located in sub-folders containing the web page calls the functions in the scripts.  Commonly used tools for downloading entire websites include HTTrack5, which has a Windows version called as WinHTTrack, as well as the 'wget' which is a command-line tool, etc. Most of these tools have options for filtering the files that get downloaded from the website, and the levels to which hyperlinks within the downloaded pages are followed and downloaded. Of course, these tools will not download the PHP or ASP scripts, but will instead show their processed outputs.
	</para>
	<para>Another file that deserves specific mention is the 'robots.txt' file. This file contains a list of folders within the website that must be ignored by search engine robots. Most search engine robots do not take this file into cognizance. However, most automated attack tools as well as attackers will look around for the presence of this file, as it will indicate potentially sensitive areas, which may contain files with critical information.
	</para>
</sect1>
<sect1>
	<title>Mitigation Techniques</title>
	<para>The first mitigation measure is to secure your web server. Apply all the security patches for your web server and the underlying operating system. Use commonly available patch checking tools to determine missing patches. Follow secure coding guidelines for the specific web server. Some of these would be to run the web server with normal user privileges, remove sample scripts and files, remove any CGI scripts that are absolutely not required (such as formmail.pl, etc.), remove all features/modules that are not necessary for your website to function, etc.
	</para>
	<para>Additionally, use utilities or configuration changes to ensure that your webserver does not reveal its actual name and version in the banner. You may use URLScan for Microsoft IIS and modify the httpd.conf to prevent Apache from revealing its version number. Also, you should customize the error pages as they immediately indicate the web server being used.
	</para>
	<para>To prevent important configuration files such as .inc, .cfg, .config, etc. from being downloaded, you could rename them to have .php or .asp extensions, such that the web server will attempt to preprocess them, and the contents will not get revealed to the attacker. A better solution is to put these files outside of the $DocumentRoot, such that they cannot be accessed simply by typing in the path as a URL.
	</para>
</sect1>

