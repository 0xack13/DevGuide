<sect1>
	<title>Canonical Attacks</title>
	<para>Canonicalization deals with the way in which systems convert data from one form to another. Canonical means the simplest or most standard form of something. Canonicalization is the process of converting something from one representation to  the simplest form. Web applications have to deal with lots of canonicalization issues  from URL encoding to IP address translation. When security decisions are made based on canonical forms of data, it is therefore essential that the application is able  to deal with canonicalization issues accurately.
	</para>
	
	<sect2>
		<title>URL Encoding</title>
		<para>The RFC 1738 specification defining Uniform Resource Locators (URLs) and the RFC 2396 specification for Uniform Resource Identifiers (URIs) both restrict the characters allowed in a URL or URI to a subset of the US-ASCII character set. According to the RFC 1738 specification, &quot;only alphanumerics, the special characters &quot;$-_.+!*&apos;(),&quot;, and reserved characters used for their reserved purposes may be used unencoded within a URL.&quot; The data used by a web application, on the other hand, is not restricted in any way and in fact may be represented by any existing character set or even binary data. Earlier versions of HTML allowed the entire range of the ISO-8859-1 (ISO Latin-1)  character set; the HTML 4.0 specification expanded to permit any character in the Unicode character set.
		</para>
		<para>URL-encoding a character is done by taking the character&apos;s 8-bit hexadecimal code and prefixing it with a percent sign (&quot;%&quot;). For example, the US-ASCII character set represents a space with decimal code 32, or hexadecimal 20. Thus its URL-encoded representation is %20. Even though certain characters do not need to be URL-encoded, any 8-bit code (i.e., decimal 0-255 or hexadecimal 00-FF) may be encoded. ASCII control characters such as the NULL character (decimal code 0) can be URL-encoded, as can all HTML entities and any meta characters used by the operating system or database. Because URL-encoding allows virtually any data to be passed to the server, proper precautions must be taken by a web application when accepting data. URL-encoding can be used as a mechanism for disguising many types of malicious code.
		</para>
		<para>
		Here is a SQL Injection example that shows how this attack can be accomplished.
		</para>
		<para>
		Original database query in search.asp:
		</para>
		<screen>
		sql = "SELECT lname, fname, phone FROM usertable WHERE lname='"
		</screen>
		<para>
		HTTP request:
		</para>
		<screen>
		http://www.myserver.com/search.asp?lname=smith%27%3bupdate%20usertable%
		</screen>
		<para>
		Executed database query:
		</para>
		<screen>
		SELECT lname, fname, phone FROM usertable WHERE lname='smith'; update usertable
		</screen>

		<para>
		A suitable canonical form should be chosen and all user input canonicalized into that form before any authorization decisions are performed. Security checks should be carried out after decoding is completed. It is usually the web server itself that decodes the URL and hence this problem may only occur on the web server itself. 
		</para>	
	</sect2>
	
	<sect2>
		<title>Unicode</title>
		<para>Unicode Encoding is a method for storing characters with multiple bytes. Wherever input data is allowed, data can be entered using Unicode to disguise malicious code and permit a variety of attacks. RFC 2279 references many ways that text can be encoded.
		</para>
		<para>
		Unicode was developed to allow a Universal Character Set (UCS) that encompasses most of the world's writing systems. Multi-octet characters, however, are not compatible with many current applications and protocols, and this has led to the development of a few UCS transformation formats (UTF) with varying characteristics. UTF-8 has the characteristic of preserving the full US-ASCII range. It is compatible with file systems, parsers and other software relying on US-ASCII values, but it is transparent to other values.
		</para>
		<para>The importance of UTF-8 representation stems from the fact that web-servers/applications perform several steps on their input of this format. The order of the steps is sometimes critical to the security of the application. Basically, the steps are "URL decoding" potentially followed by "UTF-8 decoding", and intermingled with them are various security checks, which are also processing steps.
		</para>
		<para>If, for example, one of the security checks is searching for "..", and it is carried out before UTF-8 decoding takes place, it is possible to inject ".." in their overlong UTF-8 format. Even if the security checks recognize some of the non-canonical format for dots, it may still be that not all formats are known to it. 
		</para>
		<para>Consider the ASCII character "." (dot). Its canonical representation is a dot (ASCII 2E). Yet if we think of it as a character in the second UTF-8 range (2 bytes), we get an overlong representation of it, as C0 AE. Likewise, there are more overlong representations: E0 80 AE, F0 80 80 AE, F8 80 80 80 AE and FC 80 80 80 80 AE.
		</para>
		<para>
		Table 
		UCS-4 Range
		UTF-8 encoding
		0x00000000-0x0000007F
		0xxxxxxx
		0x00000080 - 0x000007FF
		110xxxxx 10xxxxxx
		0x00000800-0x0000FFFF
		1110xxxx 10xxxxxx 10xxxxxx
		0x00010000-0x001FFFFF
		11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
		0x00200000-0x03FFFFFF
		111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
		0x04000000-0x7FFFFFFF
		1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
		</para>
		<para>Consider the representation C0 AE of a ".". Like UTF-8 encoding requires, the second octet has "10" as its two most significant bits. Now, it is possible to define 3 variants for it, by enumerating the rest of the possible 2 bit combinations ("00", "01" and "11"). Some UTF-8 decoders would treat these variants as identical to the original symbol (they simply use the least significant 6 bits, disregarding the most significant 2 bits). Thus, the 3 variants are C0 2E, C0 5E and C0 FE.
		</para>
		<para>It is thus possible to form illegal UTF-8 encodings, in two senses:
		</para>
		
		<itemizedlist mark="opencircle" spacing="compact">
			<listitem>
				<para>A UTF-8 sequence for a given symbol may be longer than necessary for representing the symbol. 
				</para>
			</listitem>
			<listitem>
				<para>A UTF-8 sequence may contain octets that are in incorrect format (i.e. do not comply with the above 6 formats).
				</para>
			</listitem>
		</itemizedlist>
		
		<para>To further "complicate" things, each representation can be sent over HTTP in several ways:
		</para>
		
		<itemizedlist mark="opencircle" spacing="compact">
			<listitem>
				<para>In the raw. That is, without URL encoding at all. This usually results in sending non-ASCII octets in the path, query or body, which violates the HTTP standards. Nevertheless, most HTTP servers do get along just fine with non-ASCII characters.
				</para>
			</listitem>
			<listitem>
				<para>Valid URL encoding. Each non-ASCII character (more precisely, all characters that require URL encoding - a superset of non ASCII characters) is URL-encoded. This results in sending, say, %C0%AE.
				</para>
			</listitem>
			<listitem>
				<para>Invalid URL encoding. This is a variant of valid URL encoding, wherein some hexadecimal digits are replaced with non-hexadecimal digits, yet the result is  still interpreted as identical to the original, under some decoding algorithms. For example, %C0 is interpreted as character number ('C'-'A'+10)*16+('0'-'0') = 192. Applying the same algorithm to %M0 yields ('M'-'A'+10)*16+('0'-'0') = 448, which, when forced into a single byte, yields (8 least significant bits) 192, just like the original. So, if the algorithm is willing to accept non-hexadecimal digits (such as 'M'), then it is possible to have variants for %C0 such as %M0 and %BG.
				</para>
			</listitem>
		</itemizedlist>

		<para>It should be kept in mind that these techniques are not directly related to Unicode, and they can be used in non-Unicode attacks as well. 
		</para>
		
		<screen>http://host/cgi-bin/bad.cgi?foo=../../bin/ls%20-al</screen>
		
		<para>URL Encoding of the example attack:
		</para>
		
		<screen>http://host/cgi-bin/bad.cgi?foo=..%2F../bin/ls%20-al</screen>

		<para>Unicode encoding of the example attack:</para>
		
		<screen>
		http://host/cgi-bin/bad.cgi?foo=..%c0%af../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%9c../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%pc../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c0%9v../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c0%qf../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%8s../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%1c../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%9c../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%c1%af../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%e0%80%af../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%f0%80%80%af../bin/ls%20-al
		http://host/cgi-bin/bad.cgi?foo=..%f8%80%80%80%af../bin/ls%20-al
		</screen>
		
	</sect2>
</sect1>

<sect1>
	<title>Mitigation techniques</title>
	<para>A suitable canonical form should be chosen and all user input canonicalized into that form before any authorization decisions are performed. Security checks should be  carried out after UTF-8 decoding is completed. Moreover, it is recommended to check that the UTF-8 encoding is a valid canonical encoding for the symbol it represents.
	</para>
	<para>http://www.ietf.org/rfc/rfc2279.txt?number=2279</para>
</sect1>

