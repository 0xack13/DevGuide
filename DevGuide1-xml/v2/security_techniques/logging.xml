<!-- $Id: logging.xml,v 1.3 2004/05/11 21:06:24 awiesmann Exp $ -->

<sect1>
   <title>Introduction</title>

   <para>Many applications use log files in any form. This can range from a simple file written by the hosting web server to a extensive log file containing all informations and movements of a user working with an application.</para>

   <para>Often logs are used during development and forgotten later on during the roll out at the customers site. These logs are known to be misused by attackers either to learn more about the attacked system or as a general information leak.</para>

   <para>This chapter is all about the zen of logging. It is therefor answering the following questions:</para>

   <itemizedlist mark="opencircle" spacing="compact">
      <listitem>
         <para>Motivation</para>

         <para>Why do we log something in the first place?</para>
      </listitem>

      <listitem>
         <para>Logging types</para>

         <para>What can or should be logged and where does the data come from?</para>
      </listitem>

      <listitem>
         <para>Storage and handling</para>

         <para>Where are logs stored to? How are log files handled and who should have access to them?</para>
      </listitem>

      <listitem>
         <para>Attacks and mitigation stategies</para>

         <para>How can and will logs be attacked and how can we protect the files?</para>
      </listitem>
   </itemizedlist>
</sect1>

<sect1>
   <title>Motivation</title>

   <para>Normaly there is some reason behind the decision to log informations from within an application. Among the possible reasons to do so can be some from the following list:</para>

   <itemizedlist mark="opencircle" spacing="compact">
      <listitem>
         <para>General Debugging</para>

         <para>Logs are useful in reconstructing events after a problem has occurred, security related or not.</para>

         <para>Event reconstruction can allow a security administrator to determine the full extent of an intruder's activities and expedite the recovery process.</para>
      </listitem>

      <listitem>
         <para>Potential forensics</para>

         <para>Logs may in some cases be needed in legal proceedings to prove wrongdoing. In this case, the actual handling of the log data is crucial.</para>
      </listitem>

      <listitem>
         <para>Traceability of behaviour</para>

         <para>Logs are often the only record that suspicious behavior is taking place: Therefor logs can sometimes be fed real-time directly into intrusion detection systems.</para>
      </listitem>

      <listitem>
         <para>Quality of service</para>

         <para>Repetitive polls can be protocolled so that network outages or server shutdowns get protocolled and the bahaviour can either be analyzed later on or a responsible person can take immediate actions.</para>
      </listitem>

      <listitem>
         <para>Proof of validity</para>

         <para>Application developers sometimes write logs to proof to their customers that their applications are behaving as expected and the error must be searched somewhere else.</para>
      </listitem>

      <listitem>
         <para>Required by law or corporate policies</para>

         <para>Logs can provide individual accountability in the web application system universe by tracking a user's actions.</para>

         <para>It can be corporate policy or local law to be required to (as example) save header informations of all incoming and outgoing emails. These logs must then be kept save and confidential for six months before they can be deleted.</para>
      </listitem>
   </itemizedlist>

   <para>The points from above show all different motivations and result in different requirements and strategies. This means, that before we can implement a logging mechanism into an application or system, we have to know the requirements and their later usage. If we fail in doing so this can lead to unintentional results.</para>

   <para>Failure to enable or design the proper event logging mechanisms in the web application may undermine an organization's ability to detect unauthorized access attempts, and the extent to which these attempts may or may not have succeeded. We will look into the most common attack methods, design and implementation errors as well as the mitigation strategies later on in this chapter.</para>

   <para>There is another reason why the logging mechanism must be planned before it's implementation. In some countries there exist laws which define what kind of personal informations are allowed to be not only logged but also analyzed. In Switzerland - as example - companies are not allowed to log personal informations of their employes (like what they do on the internet or what they write in their emails). So if a company wants to log a workers surfing habbits, the corporation needs to inform her of their plans in advance.</para>

   <para>This leads to the requirement of having anonymized logs or unpersonalized logs with the ability to re-personalized them later on if need be. If an unauthorized person has access to (legally) personalized logs, the corporation is acting unlawful again. So there can be a few (not only) legal traps which must be kept in mind.</para>
</sect1>

<sect1>
   <title>Logging types</title>

   <para>Logs can contain different kinds of data. The selection of the data used is normaly affected by the motivation leading to the logging. This section contains informations about the different types of logging informations and the reasons why we could want to log them.</para>

   <para>In general, the logging features include appropriate debugging informations such as time of event, initiating process or owner of process, and a detailed description of the event. The following are types of system events which can be logged in an application. It depends on the particular applicaton or system and the needs to decide which of these will be used in the logs:</para>

   <itemizedlist mark="opencircle" spacing="compact">
      <listitem>
         <para>Reading of data logs file access and what kind of data is read. This not only allows to see if data was read but also by whom and when.</para>
      </listitem>

      <listitem>
         <para>Writing of data logs also where and with what mode (append, replace) data was written. This can be used to see if data was overwritten or if a program is writing at all.</para>
      </listitem>

      <listitem>
         <para>Modification of any data characteristics, including access control permissions or labels, location in database or file system, or data ownership. Administrators can detect if their configurations were changed.</para>
      </listitem>

      <listitem>
         <para>All administrative functions and changes in configuration regardless of overlap (account management actions, viewing any user's data, enabling or disabling logging, etc.)</para>
      </listitem>

      <listitem>
         <para>Miscellaneous debugging information that can be enabled or disabled on the fly.</para>
      </listitem>

      <listitem>
         <para>All authorization attempts (include time) like success/failure, resource or function being authorized, and the user requesting authorization. We can detect password guessing with these logs. These kinds of logs can be fed into an Intrusion Detection system which will detect anomalies.</para>
      </listitem>

      <listitem>
         <para>Deletion of any data (object). Sometimes applications are required to have some sort of versioning in which the deletion process can be cancelled.</para>
      </listitem>

      <listitem>
         <para>Network communications (bind, connect, accept, etc.). With these informations an Intrusion Detection system can detect port scanning and brute force attacks.</para>
      </listitem>

      <listitem>
         <para>All authentication events (logging in, logging out, failed logins, etc.) which allow to detect brute force and guessing attacks too.</para>
      </listitem>
   </itemizedlist>
</sect1>

<sect1>
   <title>Attacks and mitigation stategies</title>

   <para>There are a number of attacks against logging mechanisms of which a security administrator should be aware of in order to decide on suitable protection measures:</para>

   <sect2>
      <title>Noise</title>

      <sect3>
         <title>Description</title>

         <para>Intentionally invoking security errors to fill an error log with entries (noise) that hide the incriminating evidence of a successful intrusion.  When the administrator or log parser application reviews the logs, there is every chance that they will summarize the volume of log entries as a denial of service attempt rather than identifying the 'needle in the haystack'.</para>
      </sect3>

      <sect3>
         <title>Mitigation Techniques</title>

         <para>This is difficult since applications usually offer an uminpeded route to functions capable of generating log events.  If you can deploy an intelligent device or application component that can shun an attacker after repeated attempts, then that would be beneficial.  Failing that, an error log audit tool that can reduce the bulk of the noise, based on repetition of events or originating from the same source for example.  It is also useful if the log viewer can display the events in order of severity level, rather than just time based.</para>
      </sect3>
   </sect2>

   <sect2>
      <title>Cover Tracks</title>

      <sect3>
         <title>Description</title>

         <para>The top prize in logging mechanism attacks goes to the contender who can delete or manipulate log entries at a granular level, "as though the event never even happened!".  Intrusion and deployment of rootkits allows an attacker to utilize specialized tools that may assist or automate the manipulation of known log files.  In most cases, log files may only be manipulated by users with root / administrator privileges, or via approved log manipulation applications.  As a general rule, logging mechanisms should aim to prevent manipulation at a granular level since an attacker can hide their tracks for a considerable length of time without being detected.  Simple question; if you were being compromised by an attacker, would the intrusion be more obvious if your log file was abnormally large or small, or if it appeared like every other day's log?</para>
      </sect3>

      <sect3>
         <title>Mitigation Techniques</title>

         <para>Assign log files the highest security protection, providing reassurance that you always have an effective 'black box' recorder if things go wrong.  This includes:</para>
      
      <itemizedlist mark="opencircle" spacing="compact">
      <listitem>
         <para>Applications should not run against user IDs assigned as 'superusers'.  This is the main cause of log file manipulation success since superusers typically have full file system access.  Assume the worst case scenario and suppose your application is expolited.  Would there be any other security layers in place to prevent the application's user privileges from manipulating the log file to cover tracks?</para>
      </listitem>
      
      <listitem>
         <para>Ensuring that access privileges protecting the log files are restrictive, reducing the majority of operations against the log file to alter and read.</para>
      </listitem>
      
      <listitem>
         <para>Ensuring that log files are assigned object names that are not obvious and stored in a safe location of the file system.</para>
      </listitem>

	  <listitem>
         <para>Writing log files using publicly or formally scrutinized techniques in an attempt to reduce the risk associated with reverse engineering or log file manipulation.</para>
      </listitem>
      
      <listitem>
         <para>Writing log files to Read Only media (where event log integrity is of critical importance).</para>
      </listitem>
      
      <listitem>
         <para>Use of hashing technology to create digital fingerprints.  The idea being that if an attacker does manipulate the log file, then the digital fingerprint will not match and an alert generated.</para>
      </listitem>
      
      <listitem>
         <para>Use of host based IDS technology where normal behavioral patterns can be 'set in stone'.  Attempts by attackers to update the log file through anything but the normal approved flow would generate an exception and the intrusion can be detected and blocked.  This is one security control that can safeguard against simplistic administrator attempts at modifications.</para>
      </listitem>
     </itemizedlist>
    </sect3>
   </sect2>

   <sect2>
      <title>False Alarms</title>

      <sect3>
         <title>Description</title>

         <para>Taking cue from the classic 1966 film "How to Steal a Million", or similarly the fable of Aesop; "The Boy Who Cried Wolf", be wary of repeated false alarms, since this may represent an attacker's actions in trying to fool the security admnistrator into thinking that the technology is faulty and not to be trusted until it can be fixed.</para>
      </sect3>

      <sect3>
         <title>Mitigation Techniques</title>

         <para>Simply be aware of this type of attack, take every security violation seriously, always get to the bottom of the cause event log errors rather, and don't just dismiss errors unless you can be completely sure that you know it to be a technical problem.</para>
      </sect3>
   </sect2>
   
   <sect2>
      <title>Denial of Service</title>

      <sect3>
         <title>Description</title>

         <para>There are a couple of scenarios here:</para>
      
      		<itemizedlist mark="opencircle" spacing="compact">
      		<listitem>
         		<para>By repeatedly hitting an application with requests that cause log entries to be written, multiply this by ten thousand, and the result is that you have a very large log file and a possible headache for the security administrator.  Where log files are configured with a fixed allocation size, then once full, all logging will stop and an attacker has effectively denied service to your logging mechanism.  Worse still, if there is no maximum log file size, then an attacker has the ability to completely fill the hard drive partition and potentially deny service to the entire system.  This is becoming more of a rarity though with the increasing size of today's hard disks, although you could argue that network bandwidth and processing power is also increasing at a similar rate, thus an attacker has increased ability to fire ammunition at a faster rate.</para>
      		</listitem>
		</itemizedlist>
      
      </sect3>

      <sect3>
         <title>Mitigation Techniques</title>

         <para>The main defense against this type of attack are to increase the maximum log file size to a value that is unlikely to be reached, place the log file on a separate partition to that of the operating system or other critical applications and best of all, try to deploy some kind of system monitoring application that can set a threshold against your log file size and/or activity and issue an alert if an attack of this nature is underway.</para>
      </sect3>
   </sect2>
   
   <sect2>
      <title>Destruction</title>

      <sect3>
         <title>Description</title>

         <para>There are a couple of scenarios here:</para>
      
      		<itemizedlist mark="opencircle" spacing="compact">
      		<listitem>
         		<para>Following the same scenario as the Denial of Service above, if a log file is configured to cycle round overwriting old entries when full, then an attacker has the potential to do the evil deed and then set a log generation script into action in an attempt to eventually overwrite the incriminating log entries, thus destroying them.</para>
      		</listitem>
      		
      		<listitem>
         		<para>If all else fails, then an attacker may simply choose to cover their tracks by purging all log file entries, assuming they have the privileges to perform such actions.  This attack would most likely involve calling the log file management program and issuing the command to clear the log, or it may be easier to simply delete the object which is receiving log event updates (in most cases, this object will be locked by the application).  This type of attack does make an intrusion very obvious assuming that log files are being regularly monitored, and does have a tendancy to cause panic as system administrators and managers realize they have nothing upon which to base an investigation on.</para>
         	</listitem>
		</itemizedlist>
      </sect3>

      <sect3>
         <title>Mitigation Techniques</title>

         <para>Following most of the techniques suggested above will provide good protection against this attack.  Also keep in mind two things;  (1) Administrative users of the system should be well trained in log file management and review.  'Ad-hoc' clearing of log files is never advised and an archive should always be taken.  Too many times a log file is cleared, perhaps to assist in a technical problem, erasing the history of events for possible future investagative purposes. (2) An empty security log does not necesarilly mean that you should pick up the phone and fly the forensics team in.  In some cases, security logging is not turned on by default and it is up to you to make sure that it is.  Also, make sure it is logging at the right level of detail and benchmark the errors against an established baseline in order measure what is considered 'normal' activity.</para>
      </sect3>
   </sect2>
   
</sect1>

<sect1>
   <title>Best practices</title>

   <para>It is just as important to have effective log management and collection facilities so that the logging capabilities of the web server and application are not wasted. Failure to properly store and manage the information being produced by your logging mechanisms could place this data at risk of compromise and make it useless for post mortem security analysis or legal prosecution. Ideally logs should be collected and consolidated on a separate dedicated logging host. The network connections or actual log data contents should be encrypted to both protect confidentiality and integrity if possible.</para>

   <sect2>
      <title>Storage</title>

      <para>Where to log to?</para>

      <para>Logs should be written so that the log file attributes are such that only new information can be written (older records cannot be rewritten or deleted). For added security, logs should also be written to a write once / read many device such as a CD-R.</para>

      <para>Copies of log files should be made at regular intervals depending on volume and size (daily, weekly, monthly, etc.). .). A common naming convention should be adopted with regards to logs, making them easier to index. Verification that logging is still actively working is overlooked surprisingly often, and can be accomplished via a simple cron job!</para>

      <para>Make sure data is not overwritten.</para>

      <para>Log files should be copied and moved to permanent storage and incorporated into the organization's overall backup strategy.</para>

      <para>Log files and media should be deleted and disposed of properly and incorporated into an organization's shredding or secure media disposal plan. Reports should be generated on a regular basis, including error reporting and anomaly detection trending.</para>

      <para>Be sure to keep logs safe and confidential even when backed up.</para>
   </sect2>

   <sect2>
      <title>Handling</title>

      <para>Logs can be fed into real time intrusion detection and performance and system monitoring tools. All logging components should be synced with a timeserver so that all logging can be consolidated effectively without latency errors. This time server should be hardened and should not provide any other services to the network.</para>

      <para>No manipulation, no deletion while analyzing.</para>
   </sect2>
</sect1>

<sect1>
   <title>Summary</title>

   <para>This chapter covered the motivation behind the act of writing logs, how to avoid problems with and how to handle log files:</para>

   <itemizedlist mark="opencircle" spacing="compact">
      <listitem>
         <para>Reason</para>

         <para>The motivation of writing logs and the reason for the logged values.</para>
      </listitem>

      <listitem>
         <para>Storage</para>

         <para>How to store and evaluate logs.</para>
      </listitem>

      <listitem>
         <para>Attacks</para>

         <para>The different kinds of attacks against logs and how to detect, defeat and avoid them.</para>
      </listitem>
   </itemizedlist>
</sect1>

